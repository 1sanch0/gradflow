{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradflow import Tensor\n",
    "from gradflow.model import Model\n",
    "import gradflow.functions as F\n",
    "from gradflow.optim import *\n",
    "\n",
    "from datasets.mnist import MNISTDataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Model):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.dense0 = F.Linear(28*28, 16)\n",
    "    self.relu = F.ReLU()\n",
    "    self.dense1 =  F.Linear(16, 10)\n",
    "    self.logsoftmax = F.LogSoftmax(dim=-1)\n",
    "  \n",
    "  def forward(self, x) -> Tensor:\n",
    "    out = self.dense0(x)\n",
    "    out = self.relu(out)\n",
    "    out = self.dense1(out)\n",
    "    return self.logsoftmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-images-idx3-ubyte.gz already exists in ../data. Skipping...\n",
      "t10k-images-idx3-ubyte.gz already exists in ../data. Skipping...\n",
      "train-labels-idx1-ubyte.gz already exists in ../data. Skipping...\n",
      "t10k-labels-idx1-ubyte.gz already exists in ../data. Skipping...\n",
      "train-images-idx3-ubyte.gz already exists in ../data. Skipping...\n",
      "t10k-images-idx3-ubyte.gz already exists in ../data. Skipping...\n",
      "train-labels-idx1-ubyte.gz already exists in ../data. Skipping...\n",
      "t10k-labels-idx1-ubyte.gz already exists in ../data. Skipping...\n"
     ]
    }
   ],
   "source": [
    "train_dset = MNISTDataset(\"../data/\", batch_size=32*3)\n",
    "test_dset = MNISTDataset(\"../data/\", batch_size=10, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testit(dset, model, criterion):\n",
    "  loss = 0\n",
    "  corrects = 0\n",
    "  for imgs, labels in dset:\n",
    "    outputs = model(imgs)\n",
    "    loss += criterion(outputs, labels).data\n",
    "\n",
    "    preds = outputs.data.argmax(axis=1)\n",
    "    labels = labels.data.argmax(axis=1)\n",
    "    corrects += ((preds == labels).sum() / labels.size)\n",
    "\n",
    "  return loss / len(dset), corrects / len(dset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "criterion = F.NLLLoss(indexed=False)\n",
    "optimizer = Adam(model.parameters(), 0.001, 0.001)\n",
    "# optimizer = RMSprop(model.parameters(), 0.001, 0.001, 0.99)\n",
    "# optimizer = SGD(model.parameters(), 0.001, 0.001, 0.9, False)\n",
    "# optimizer = Adagrad(model.parameters(), 0.01, 0.001, eps=1e-4)\n",
    "# optimizer = SGD(model.parameters(), 0.001, 0, 0., True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================\n",
      "Last 500 train | avg. loss: 1.0776, acc: 0.6725\n",
      "Test           | avg. loss: 0.4523, acc: 0.8678\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.3751, acc: 0.8895\n",
      "Test           | avg. loss: 0.3180, acc: 0.9082\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.3019, acc: 0.9115\n",
      "Test           | avg. loss: 0.2733, acc: 0.9222\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.2633, acc: 0.9231\n",
      "Test           | avg. loss: 0.2459, acc: 0.9275\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.2379, acc: 0.9311\n",
      "Test           | avg. loss: 0.2268, acc: 0.9337\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.2209, acc: 0.9359\n",
      "Test           | avg. loss: 0.2136, acc: 0.9371\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.2088, acc: 0.9394\n",
      "Test           | avg. loss: 0.2038, acc: 0.9414\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1998, acc: 0.9421\n",
      "Test           | avg. loss: 0.1960, acc: 0.9437\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1929, acc: 0.9438\n",
      "Test           | avg. loss: 0.1908, acc: 0.9448\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1873, acc: 0.9457\n",
      "Test           | avg. loss: 0.1867, acc: 0.9471\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1827, acc: 0.9476\n",
      "Test           | avg. loss: 0.1832, acc: 0.9479\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1789, acc: 0.9487\n",
      "Test           | avg. loss: 0.1809, acc: 0.9489\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1759, acc: 0.9496\n",
      "Test           | avg. loss: 0.1791, acc: 0.9497\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1734, acc: 0.9503\n",
      "Test           | avg. loss: 0.1774, acc: 0.9500\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1712, acc: 0.9510\n",
      "Test           | avg. loss: 0.1758, acc: 0.9509\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1691, acc: 0.9515\n",
      "Test           | avg. loss: 0.1740, acc: 0.9511\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1674, acc: 0.9522\n",
      "Test           | avg. loss: 0.1728, acc: 0.9514\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1658, acc: 0.9527\n",
      "Test           | avg. loss: 0.1718, acc: 0.9516\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1643, acc: 0.9534\n",
      "Test           | avg. loss: 0.1707, acc: 0.9522\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1628, acc: 0.9538\n",
      "Test           | avg. loss: 0.1699, acc: 0.9521\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1616, acc: 0.9543\n",
      "Test           | avg. loss: 0.1694, acc: 0.9525\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1605, acc: 0.9547\n",
      "Test           | avg. loss: 0.1688, acc: 0.9526\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1594, acc: 0.9550\n",
      "Test           | avg. loss: 0.1681, acc: 0.9532\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1583, acc: 0.9554\n",
      "Test           | avg. loss: 0.1676, acc: 0.9530\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1574, acc: 0.9557\n",
      "Test           | avg. loss: 0.1667, acc: 0.9530\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1565, acc: 0.9561\n",
      "Test           | avg. loss: 0.1662, acc: 0.9529\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1557, acc: 0.9562\n",
      "Test           | avg. loss: 0.1656, acc: 0.9524\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1549, acc: 0.9562\n",
      "Test           | avg. loss: 0.1651, acc: 0.9521\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1541, acc: 0.9563\n",
      "Test           | avg. loss: 0.1642, acc: 0.9525\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1533, acc: 0.9563\n",
      "Test           | avg. loss: 0.1640, acc: 0.9525\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1525, acc: 0.9566\n",
      "Test           | avg. loss: 0.1634, acc: 0.9520\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1518, acc: 0.9568\n",
      "Test           | avg. loss: 0.1633, acc: 0.9519\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1512, acc: 0.9571\n",
      "Test           | avg. loss: 0.1625, acc: 0.9524\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1506, acc: 0.9570\n",
      "Test           | avg. loss: 0.1623, acc: 0.9525\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1500, acc: 0.9573\n",
      "Test           | avg. loss: 0.1622, acc: 0.9521\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1493, acc: 0.9574\n",
      "Test           | avg. loss: 0.1616, acc: 0.9521\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1489, acc: 0.9574\n",
      "Test           | avg. loss: 0.1614, acc: 0.9520\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1484, acc: 0.9578\n",
      "Test           | avg. loss: 0.1611, acc: 0.9526\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1480, acc: 0.9579\n",
      "Test           | avg. loss: 0.1611, acc: 0.9526\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1476, acc: 0.9580\n",
      "Test           | avg. loss: 0.1607, acc: 0.9526\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1471, acc: 0.9581\n",
      "Test           | avg. loss: 0.1605, acc: 0.9530\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1468, acc: 0.9583\n",
      "Test           | avg. loss: 0.1603, acc: 0.9532\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1464, acc: 0.9583\n",
      "Test           | avg. loss: 0.1602, acc: 0.9525\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1461, acc: 0.9584\n",
      "Test           | avg. loss: 0.1599, acc: 0.9533\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1457, acc: 0.9585\n",
      "Test           | avg. loss: 0.1598, acc: 0.9530\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1455, acc: 0.9587\n",
      "Test           | avg. loss: 0.1598, acc: 0.9532\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1451, acc: 0.9589\n",
      "Test           | avg. loss: 0.1595, acc: 0.9533\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1449, acc: 0.9589\n",
      "Test           | avg. loss: 0.1593, acc: 0.9534\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1447, acc: 0.9591\n",
      "Test           | avg. loss: 0.1592, acc: 0.9538\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.1444, acc: 0.9593\n",
      "Test           | avg. loss: 0.1594, acc: 0.9541\n",
      "=============================\n"
     ]
    }
   ],
   "source": [
    "training_loss = []\n",
    "corrects = []\n",
    "for epoch in range(50):\n",
    "  for i, (imgs, labels) in enumerate(train_dset):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(imgs)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    training_loss += [loss.data]\n",
    "    preds = outputs.data.argmax(axis=1)\n",
    "    labels = labels.data.argmax(axis=1)\n",
    "    corrects += [(preds == labels).sum() / labels.size]\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if ((i + 1) % 500 == 0):\n",
    "      test_loss, test_acc = testit(test_dset, model, criterion)\n",
    "      print(\"=============================\")\n",
    "      print(\"Last 500 train | avg. loss: %.4f, acc: %.4f\" \\\n",
    "            % (np.mean(training_loss[-500:]), np.mean(corrects[-500:])))\n",
    "      print(\"Test           | avg. loss: %.4f, acc: %.4f\" % (test_loss, test_acc))\n",
    "      print(\"=============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe33f9eec50>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 3\n",
    "\n",
    "true_imgs, true_labels = test_dset[batch]\n",
    "labels = true_labels.data.argmax(axis=1)\n",
    "preds = model(true_imgs)\n",
    "preds_labels = preds.data.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 3, 4, 7, 2, 7, 1, 2, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.22963686e+01, -1.06853361e+01, -1.34235296e+01,\n",
       "        -1.07069910e-02, -1.47412663e+01, -5.20916557e+00,\n",
       "        -1.71721859e+01, -8.15081596e+00, -9.63627243e+00,\n",
       "        -5.33903408e+00],\n",
       "       [-8.69376755e+00, -2.66492367e-02, -6.38229275e+00,\n",
       "        -4.45149422e+00, -6.98922539e+00, -7.70796490e+00,\n",
       "        -7.50974941e+00, -5.75273228e+00, -6.87925053e+00,\n",
       "        -5.01231575e+00],\n",
       "       [-1.30386600e+01, -1.02942181e+01, -1.34047298e+01,\n",
       "        -5.02651706e-02, -1.08119230e+01, -3.04908919e+00,\n",
       "        -1.52616520e+01, -1.51830015e+01, -6.73878145e+00,\n",
       "        -7.87913609e+00],\n",
       "       [-5.00833988e-01, -1.39844332e+01, -5.48223019e+00,\n",
       "        -1.11533155e+01, -3.39144802e+00, -4.77027130e+00,\n",
       "        -1.06724644e+00, -6.54211521e+00, -7.76093292e+00,\n",
       "        -6.29808235e+00],\n",
       "       [-1.16099348e+01, -1.36051455e+01, -6.99049997e+00,\n",
       "        -5.92318153e+00, -1.27278643e+01, -1.27561579e+01,\n",
       "        -1.59285803e+01, -3.96656059e-03, -9.06468582e+00,\n",
       "        -8.37971687e+00],\n",
       "       [-9.29607868e+00, -5.06848764e+00, -3.16200256e-02,\n",
       "        -4.97226572e+00, -7.77414036e+00, -4.06226730e+00,\n",
       "        -1.00938931e+01, -1.52716093e+01, -8.92154408e+00,\n",
       "        -1.16375961e+01],\n",
       "       [-9.12740040e+00, -1.05275021e+01, -5.44859266e+00,\n",
       "        -6.21891403e+00, -1.32749805e+01, -1.06833448e+01,\n",
       "        -1.31979618e+01, -6.63059950e-03, -9.58342075e+00,\n",
       "        -9.38340473e+00],\n",
       "       [-9.96305847e+00, -2.71147490e-03, -8.15186882e+00,\n",
       "        -7.03244543e+00, -1.07675285e+01, -1.07710104e+01,\n",
       "        -8.34568024e+00, -8.33726978e+00, -7.18567657e+00,\n",
       "        -8.45249176e+00],\n",
       "       [-6.88262463e+00, -4.48336792e+00, -6.48728132e-01,\n",
       "        -8.85621786e-01, -1.02245169e+01, -3.04320216e+00,\n",
       "        -6.58922958e+00, -1.00187311e+01, -6.10035515e+00,\n",
       "        -6.78411007e+00],\n",
       "       [-1.06851978e+01, -8.19921494e-03, -9.83038521e+00,\n",
       "        -6.55902767e+00, -1.15335217e+01, -1.04115696e+01,\n",
       "        -8.35700035e+00, -9.08147049e+00, -5.73826122e+00,\n",
       "        -5.78836536e+00]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 3, 0, 7, 2, 7, 1, 2, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 3, 4, 7, 2, 7, 1, 2, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 1, 1, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds_labels == labels).astype(np.uint8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97cc609b13305c559618ec78a438abc56230b9381f827f22d070313b9a1f3777"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
