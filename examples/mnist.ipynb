{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradflow import Tensor\n",
    "from gradflow.model import Model\n",
    "import gradflow.functions as F\n",
    "from gradflow.optim import *\n",
    "\n",
    "from datasets.mnist import MNISTDataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(Model):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.dense0 = F.Linear(28*28, 16)\n",
    "    self.relu = F.ReLU()\n",
    "    self.dense1 =  F.Linear(16, 10)\n",
    "    self.sigmoid = F.Sigmoid()\n",
    "  \n",
    "  def forward(self, x) -> Tensor:\n",
    "    out = self.dense0(x)\n",
    "    out = self.relu(out)\n",
    "    out = self.dense1(out)\n",
    "    return self.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-images-idx3-ubyte.gz already exists in ../data. Skipping...\n",
      "t10k-images-idx3-ubyte.gz already exists in ../data. Skipping...\n",
      "train-labels-idx1-ubyte.gz already exists in ../data. Skipping...\n",
      "t10k-labels-idx1-ubyte.gz already exists in ../data. Skipping...\n",
      "train-images-idx3-ubyte.gz already exists in ../data. Skipping...\n",
      "t10k-images-idx3-ubyte.gz already exists in ../data. Skipping...\n",
      "train-labels-idx1-ubyte.gz already exists in ../data. Skipping...\n",
      "t10k-labels-idx1-ubyte.gz already exists in ../data. Skipping...\n"
     ]
    }
   ],
   "source": [
    "train_dset = MNISTDataset(\"../data/\", batch_size=32*3)\n",
    "test_dset = MNISTDataset(\"../data/\", batch_size=10, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testit(dset, model, criterion):\n",
    "  loss = 0\n",
    "  corrects = 0\n",
    "  for imgs, labels in dset:\n",
    "    outputs = model(imgs)\n",
    "    loss += criterion(outputs, labels).data\n",
    "\n",
    "    preds = outputs.data.argmax(axis=1)\n",
    "    labels = labels.data.argmax(axis=1)\n",
    "    corrects += ((preds == labels).sum() / labels.size)\n",
    "\n",
    "  return loss / len(dset), corrects / len(dset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "criterion = F.BCELoss()\n",
    "optimizer = Adam(model.parameters(), 0.001, 0.001)\n",
    "# optimizer = RMSprop(model.parameters(), 0.001, 0.001, 0.99)\n",
    "# optimizer = SGD(model.parameters(), 0.001, 0.001, 0.9, False)\n",
    "# optimizer = Adagrad(model.parameters(), 0.01, 0.001, eps=1e-4)\n",
    "# optimizer = SGD(model.parameters(), 0.001, 0, 0.9, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================\n",
      "Last 500 train | avg. loss: 0.2592, acc: 0.6125\n",
      "Test           | avg. loss: 0.1167, acc: 0.8396\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0942, acc: 0.8746\n",
      "Test           | avg. loss: 0.0801, acc: 0.8975\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0791, acc: 0.8959\n",
      "Test           | avg. loss: 0.0721, acc: 0.9074\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0732, acc: 0.9049\n",
      "Test           | avg. loss: 0.0677, acc: 0.9138\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0695, acc: 0.9103\n",
      "Test           | avg. loss: 0.0648, acc: 0.9181\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0672, acc: 0.9138\n",
      "Test           | avg. loss: 0.0630, acc: 0.9195\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0658, acc: 0.9156\n",
      "Test           | avg. loss: 0.0620, acc: 0.9207\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0649, acc: 0.9168\n",
      "Test           | avg. loss: 0.0613, acc: 0.9222\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0641, acc: 0.9178\n",
      "Test           | avg. loss: 0.0606, acc: 0.9220\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0636, acc: 0.9186\n",
      "Test           | avg. loss: 0.0601, acc: 0.9231\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0631, acc: 0.9195\n",
      "Test           | avg. loss: 0.0597, acc: 0.9241\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0628, acc: 0.9200\n",
      "Test           | avg. loss: 0.0594, acc: 0.9247\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0626, acc: 0.9203\n",
      "Test           | avg. loss: 0.0592, acc: 0.9249\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0624, acc: 0.9205\n",
      "Test           | avg. loss: 0.0591, acc: 0.9247\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0623, acc: 0.9206\n",
      "Test           | avg. loss: 0.0589, acc: 0.9253\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0622, acc: 0.9205\n",
      "Test           | avg. loss: 0.0588, acc: 0.9256\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0622, acc: 0.9204\n",
      "Test           | avg. loss: 0.0587, acc: 0.9258\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0621, acc: 0.9205\n",
      "Test           | avg. loss: 0.0586, acc: 0.9255\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0620, acc: 0.9206\n",
      "Test           | avg. loss: 0.0586, acc: 0.9254\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0620, acc: 0.9205\n",
      "Test           | avg. loss: 0.0585, acc: 0.9254\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0619, acc: 0.9206\n",
      "Test           | avg. loss: 0.0584, acc: 0.9249\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0618, acc: 0.9206\n",
      "Test           | avg. loss: 0.0582, acc: 0.9253\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0615, acc: 0.9207\n",
      "Test           | avg. loss: 0.0579, acc: 0.9253\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0613, acc: 0.9209\n",
      "Test           | avg. loss: 0.0577, acc: 0.9251\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0611, acc: 0.9209\n",
      "Test           | avg. loss: 0.0576, acc: 0.9254\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0609, acc: 0.9214\n",
      "Test           | avg. loss: 0.0574, acc: 0.9259\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0608, acc: 0.9215\n",
      "Test           | avg. loss: 0.0573, acc: 0.9260\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0606, acc: 0.9215\n",
      "Test           | avg. loss: 0.0571, acc: 0.9262\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0605, acc: 0.9213\n",
      "Test           | avg. loss: 0.0570, acc: 0.9265\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0604, acc: 0.9214\n",
      "Test           | avg. loss: 0.0569, acc: 0.9268\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0603, acc: 0.9217\n",
      "Test           | avg. loss: 0.0568, acc: 0.9270\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0602, acc: 0.9219\n",
      "Test           | avg. loss: 0.0567, acc: 0.9268\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0601, acc: 0.9220\n",
      "Test           | avg. loss: 0.0566, acc: 0.9270\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0601, acc: 0.9222\n",
      "Test           | avg. loss: 0.0566, acc: 0.9270\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0600, acc: 0.9223\n",
      "Test           | avg. loss: 0.0565, acc: 0.9269\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0600, acc: 0.9220\n",
      "Test           | avg. loss: 0.0565, acc: 0.9270\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0599, acc: 0.9220\n",
      "Test           | avg. loss: 0.0565, acc: 0.9270\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0599, acc: 0.9222\n",
      "Test           | avg. loss: 0.0565, acc: 0.9271\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0598, acc: 0.9223\n",
      "Test           | avg. loss: 0.0564, acc: 0.9272\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0598, acc: 0.9224\n",
      "Test           | avg. loss: 0.0564, acc: 0.9271\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0598, acc: 0.9226\n",
      "Test           | avg. loss: 0.0564, acc: 0.9273\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0597, acc: 0.9224\n",
      "Test           | avg. loss: 0.0563, acc: 0.9279\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0597, acc: 0.9225\n",
      "Test           | avg. loss: 0.0563, acc: 0.9277\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0597, acc: 0.9225\n",
      "Test           | avg. loss: 0.0563, acc: 0.9281\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0596, acc: 0.9226\n",
      "Test           | avg. loss: 0.0562, acc: 0.9284\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0596, acc: 0.9226\n",
      "Test           | avg. loss: 0.0562, acc: 0.9287\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0595, acc: 0.9226\n",
      "Test           | avg. loss: 0.0562, acc: 0.9288\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0595, acc: 0.9226\n",
      "Test           | avg. loss: 0.0561, acc: 0.9288\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0595, acc: 0.9226\n",
      "Test           | avg. loss: 0.0561, acc: 0.9286\n",
      "=============================\n",
      "=============================\n",
      "Last 500 train | avg. loss: 0.0594, acc: 0.9228\n",
      "Test           | avg. loss: 0.0561, acc: 0.9286\n",
      "=============================\n"
     ]
    }
   ],
   "source": [
    "training_loss = []\n",
    "corrects = []\n",
    "for epoch in range(50):\n",
    "  for i, (imgs, labels) in enumerate(train_dset):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(imgs)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    training_loss += [loss.data]\n",
    "    preds = outputs.data.argmax(axis=1)\n",
    "    labels = labels.data.argmax(axis=1)\n",
    "    corrects += [(preds == labels).sum() / labels.size]\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if ((i + 1) % 500 == 0):\n",
    "      test_loss, test_acc = testit(test_dset, model, criterion)\n",
    "      print(\"=============================\")\n",
    "      print(\"Last 500 train | avg. loss: %.4f, acc: %.4f\" \\\n",
    "            % (np.mean(training_loss[-500:]), np.mean(corrects[-500:])))\n",
    "      print(\"Test           | avg. loss: %.4f, acc: %.4f\" % (test_loss, test_acc))\n",
    "      print(\"=============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7ba7b0a6b0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 3\n",
    "\n",
    "true_imgs, true_labels = test_dset[batch]\n",
    "labels = true_labels.data.argmax(axis=1)\n",
    "preds = model(true_imgs)\n",
    "preds_labels = preds.data.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 3, 4, 7, 2, 7, 1, 2, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.98344560e-03, 1.56173809e-03, 1.37842333e-04, 9.03791249e-01,\n",
       "        5.08244593e-05, 6.20439798e-02, 2.93761317e-04, 2.14491617e-02,\n",
       "        3.50793917e-03, 5.22115007e-02],\n",
       "       [1.46295037e-03, 9.09633398e-01, 6.79431576e-03, 6.27538115e-02,\n",
       "        1.34005444e-02, 4.43685390e-02, 1.41178947e-02, 2.22509317e-02,\n",
       "        3.53669003e-02, 8.88001174e-02],\n",
       "       [9.05444787e-04, 2.85457610e-03, 1.12239039e-03, 9.35648203e-01,\n",
       "        1.11773156e-03, 2.11703673e-01, 2.31155544e-04, 5.87973220e-04,\n",
       "        9.56869591e-03, 1.16224389e-03],\n",
       "       [3.24854195e-01, 5.30540070e-04, 1.41058639e-01, 7.14496709e-05,\n",
       "        2.68374324e-01, 3.88298626e-03, 3.98942232e-01, 1.96348643e-04,\n",
       "        2.54114792e-02, 2.83844420e-03],\n",
       "       [1.92458581e-04, 4.52005974e-04, 5.68199530e-02, 2.06420366e-02,\n",
       "        7.61437928e-04, 2.45074189e-04, 1.00567686e-05, 9.26497340e-01,\n",
       "        8.02965090e-03, 5.29700611e-03],\n",
       "       [4.90545668e-03, 4.80249524e-03, 9.63730156e-01, 9.25634708e-03,\n",
       "        1.13207825e-04, 8.00867006e-03, 8.73982441e-04, 1.69007084e-03,\n",
       "        3.08815599e-03, 1.96964502e-05],\n",
       "       [1.68170698e-03, 2.51411548e-04, 1.19524179e-02, 2.65849624e-02,\n",
       "        3.09051189e-04, 2.02301219e-02, 8.05102987e-04, 8.99249852e-01,\n",
       "        1.79210142e-03, 9.92670842e-03],\n",
       "       [2.73317477e-04, 9.84740198e-01, 1.86319696e-03, 9.82202124e-03,\n",
       "        2.29214807e-03, 1.21486690e-02, 7.32037332e-03, 8.11951514e-03,\n",
       "        3.31659615e-02, 1.61358248e-02],\n",
       "       [4.84432699e-03, 1.00983204e-02, 2.42957488e-01, 1.81101605e-01,\n",
       "        2.55031009e-05, 3.98843661e-02, 1.61747579e-02, 8.30513332e-03,\n",
       "        4.21345094e-03, 5.90658921e-04],\n",
       "       [1.13392998e-04, 9.67469752e-01, 6.78351731e-04, 7.63160642e-03,\n",
       "        4.62654745e-04, 3.00315907e-03, 3.59461177e-03, 1.67625654e-03,\n",
       "        5.15393093e-02, 9.05492250e-03]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 3, 6, 7, 2, 7, 1, 2, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 3, 4, 7, 2, 7, 1, 2, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 1, 1, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds_labels == labels).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97cc609b13305c559618ec78a438abc56230b9381f827f22d070313b9a1f3777"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
