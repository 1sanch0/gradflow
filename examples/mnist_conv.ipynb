{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORK IN PROGRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradflow import Tensor\n",
    "from gradflow.model import Model\n",
    "import gradflow.functions as F\n",
    "from gradflow.optim import *\n",
    "\n",
    "from datasets.mnist import MNISTDataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net1(Model):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.conv1 = F.Conv2d(1, 16, 3)\n",
    "    # self.bn = F.BatchNorm2d(16)\n",
    "    self.maxpool1 = F.MaxPool2d(2,2)\n",
    "\n",
    "    self.dense0 = F.Linear(16*13*13, 10)\n",
    "    self.relu = F.ReLU()\n",
    "    self.logsoftmax = F.LogSoftmax(dim=-1)\n",
    "  \n",
    "  def forward(self, x) -> Tensor:\n",
    "    bs, c, h, w = x.shape\n",
    "    out = self.relu(self.conv1(x))\n",
    "    # out = self.bn(out)\n",
    "    out = self.maxpool1(out)\n",
    "    out = out.reshape(bs, -1)\n",
    "    out = self.relu(self.dense0(out))\n",
    "    return self.logsoftmax(out)\n",
    "\n",
    "# net = Net1()\n",
    "# net(Tensor(np.random.randn(1, 1, 28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = MNISTDataset(\"../data/\", batch_size=32*3, shuffle=True, flatten=False)\n",
    "test_dset = MNISTDataset(\"../data/\", batch_size=10, train=False, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dset_loss_acc(dset, model, criterion):\n",
    "  loss = 0\n",
    "  corrects = 0\n",
    "  for imgs, labels in dset:\n",
    "    outputs = model(imgs)\n",
    "    loss += criterion(outputs, labels).data\n",
    "\n",
    "    preds = outputs.data.argmax(axis=1)\n",
    "    labels = labels.data.argmax(axis=1)\n",
    "    corrects += ((preds == labels).sum() / labels.size)\n",
    "\n",
    "  return loss / len(dset), corrects / len(dset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net1()\n",
    "criterion = F.NLLLoss(indexed=False)\n",
    "optimizer = Adam(model.parameters(), 0.001, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "16*13*13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_loss = []\n",
    "corrects = []\n",
    "for epoch in range(3):\n",
    "  for i, (imgs, labels) in enumerate(train_dset):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(imgs)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    training_loss += [loss.data]\n",
    "    preds = outputs.data.argmax(axis=1)\n",
    "    labels = labels.data.argmax(axis=1)\n",
    "    corrects += [(preds == labels).sum() / labels.size]\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if ((i + 1) % 100 == 0):\n",
    "      test_loss, test_acc = dset_loss_acc(test_dset, model, criterion)\n",
    "      print(\"=============================\")\n",
    "      print(\"Last 100 train | avg. loss: %.4f, acc: %.4f\" \\\n",
    "            % (np.mean(training_loss[-100:]), np.mean(corrects[-100:])))\n",
    "      print(\"Test           | avg. loss: %.4f, acc: %.4f\" % (test_loss, test_acc))\n",
    "      print(\"=============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 3\n",
    "\n",
    "true_imgs, true_labels = test_dset[batch]\n",
    "labels = true_labels.data.argmax(axis=1)\n",
    "preds = model(true_imgs)\n",
    "preds_labels = preds.data.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(preds_labels == labels).astype(np.uint8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf02708cd20c34b8c5fbdb84cf5bc390e544dcf1e33c5533341fd4b6086ccda4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
